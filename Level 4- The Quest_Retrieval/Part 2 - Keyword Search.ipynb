{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec93fed5-8b8c-4954-bb57-c84ee8a7a95b",
   "metadata": {},
   "source": [
    "# **Level 4: The Quest: Retrieval - Retrieving relevant knowledge for your AI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6901ff70-805e-4244-a75f-d1ad8f7f09fc",
   "metadata": {},
   "source": [
    "## Part 2: Keyword Search – The Precise Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e99cc-4c2c-40b4-87be-f271df6c703f",
   "metadata": {},
   "source": [
    "\n",
    "Hello everyone, and welcome back to **Level 4: The Quest for Retrieval**. In our last session, we got a bird's-eye view of the landscape, understanding that retrieval is all about finding the right pieces of knowledge from our archives to help our LLM generate the best possible answer.\n",
    "\n",
    "We introduced the main paths on this quest: **Keyword**, **Sparse**, **Dense**, and **Hybrid** search. Each has its own strengths and is suited for a different kind of journey.\n",
    "\n",
    "Today, we're taking our first step down a specific path. We're diving deep into **Keyword Search**, the oldest, simplest, and most direct form of retrieval. Don't let its simplicity fool you; it's a powerful tool that you'll use constantly, even within more advanced systems.\n",
    "\n",
    "Think of keyword search like using a magnifying glass to find exact words or phrases in a book. Sometimes, that's *exactly* what you need\\!\n",
    "\n",
    "-----\n",
    "\n",
    "## What is Keyword Search? (The Basics of Exact Matching)\n",
    "\n",
    "At its core, the concept is incredibly straightforward.\n",
    "\n",
    "**Simple Definition:** Keyword search is a retrieval method that identifies documents or text segments based on the **literal presence** of specific words or phrases (keywords) from your query.\n",
    "\n",
    "### How it Works (A Conceptual Look)\n",
    "\n",
    "Under the hood, keyword search is all about **pattern matching**. The system scans the text and looks for an exact, character-for-character match of the terms in your query. If the sequence of characters in your query exists in the document, you have a match. It's a binary, yes-or-no operation.\n",
    "\n",
    "This is fundamentally different from how humans understand language. When you hear the word \"car,\" your brain instantly connects it to related concepts like \"automobile,\" \"vehicle,\" \"driving,\" and \"transportation.\" A basic keyword search system does not. For it, \"car\" is just the sequence of letters c-a-r. If a document contains \"automobile\" but not \"car,\" a keyword search will completely miss it.\n",
    "\n",
    "Let's look at a quick, illustrative example:\n",
    "\n",
    "  * **Your Query:** \"How do I reset my password?\"\n",
    "  * **Keywords:** \"reset\", \"password\"\n",
    "\n",
    "Now, let's see how it would fare against a few documents in our knowledge base:\n",
    "\n",
    "  * **Document 1:** \"To **reset** your **password**, please follow the instructions on our website.\"\n",
    "      * **Result:** **Match\\!** Both keywords are present exactly as typed.\n",
    "  * **Document 2:** \"For account security, you may need to change your passphrase. A passphrase is a sequence of words...\"\n",
    "      * **Result:** **No match.** Even though \"change your passphrase\" is semantically identical to \"reset your password,\" the exact keywords are missing.\n",
    "  * **Document 3:** \"If you have trouble with your **password**, this guide will help. The first step in any **reset** process is...\"\n",
    "      * **Result:** **Match\\!** The words are present, even though they are in a different order and separated by other text.\n",
    "\n",
    "This simple example reveals both the power and the primary weakness of this approach.\n",
    "\n",
    "-----\n",
    "\n",
    "## Strengths of Keyword Search (When Precision Matters)\n",
    "\n",
    "Why would we use such a seemingly rigid method? Because sometimes, rigidity is exactly what we need.\n",
    "\n",
    "  * **High Precision for Exact Matches:** This is its greatest strength. If you need to find a document that contains a specific, non-negotiable term, keyword search is your most reliable tool. Think of searching for unique identifiers like product codes (`XJ-48-B2`), error messages (`Error 0x80070005`), or legal clauses (`force majeure`). You don't want a \"similar\" error code; you want the *exact* one.\n",
    "  * **Simplicity & Speed:** Conceptually, it's the easiest search method to understand. In practice, systems built for keyword search (like traditional search engines) are highly optimized and can be incredibly fast. They often use an \"inverted index,\" which is like the index at the back of a book, mapping each word to every document it appears in.\n",
    "  * **Interpretable Results:** The results are never a mystery. A document was returned because it contains the exact word(s) you searched for. There's no complex algorithm or \"black box\" deciding what's relevant. This transparency is invaluable for debugging and building trust in your RAG system.\n",
    "  * **Cost-Effective:** Keyword search does not require generating expensive embeddings for your documents or queries. The indexing and search operations are computationally cheaper than the vector math involved in semantic search, which can lead to lower operational costs.\n",
    "\n",
    "-----\n",
    "\n",
    "## Limitations of Keyword Search (The Lexical Gap Problem)\n",
    "\n",
    "While keyword search is precise, that precision comes at a great cost. Its primary weakness is a concept so important that it has its own name: the **Lexical Gap**.\n",
    "\n",
    "### The \"Lexical Gap\" Explained\n",
    "\n",
    "The lexical gap is the mismatch between the words a user types into a search box and the words that are actually used in the documents they are looking for. It's the reason our \"reset password\" vs. \"change passphrase\" example failed.\n",
    "\n",
    "Think about all the ways you could phrase the same idea:\n",
    "\n",
    "  * **Query:** \"find cheap flights\"\n",
    "  * **Possible Document Phrasings:**\n",
    "      * \"affordable airfare\"\n",
    "      * \"low-cost plane tickets\"\n",
    "      * \"search for budget travel\"\n",
    "\n",
    "A pure keyword search for \"cheap flights\" would miss all of these perfectly relevant documents. This leads to several significant problems:\n",
    "\n",
    "  * **No Semantic Understanding:** The system doesn't understand that \"car\" and \"automobile\" mean the same thing. It also can't differentiate between contexts. A search for \"Apple\" would return documents about the fruit and the technology company indiscriminately, because it only sees the letters a-p-p-l-e.\n",
    "  * **Morphological Blindness:** It often struggles with different forms of the same word. A search for \"run\" might not find documents containing \"running\" or \"ran\".\n",
    "  * **Low Recall:** Recall is a measure of how many of the *total* relevant documents were actually found. Because of the lexical gap, keyword search often misses relevant information, resulting in low recall. This is often called a \"false negative\" – the information was there, but the system failed to find it.\n",
    "\n",
    "> #### **Key Takeaway: Precision vs. Recall**\n",
    ">\n",
    ">   * **Precision:** Of the documents you retrieved, how many were actually relevant? Keyword search is often **high-precision** (if it finds something with a specific term, it's likely relevant).\n",
    ">   * **Recall:** Of all the relevant documents that exist in your database, how many did you find? Keyword search is often **low-recall** (it misses relevant documents due to wording differences).\n",
    ">\n",
    "> In RAG, we often battle between these two. We want to find *all* the relevant information (high recall) without including a lot of junk (high precision).\n",
    "\n",
    "-----\n",
    "\n",
    "## When to Use Keyword Search in RAG Applications\n",
    "\n",
    "Given its limitations, you might wonder if keyword search has a place in modern, sophisticated RAG systems. The answer is a resounding **yes**, but rarely alone.\n",
    "\n",
    "1.  **Searching for Specific Identifiers:** This is the killer use case. When your query involves product SKUs, employee IDs, transaction numbers, or specific technical jargon that has no synonyms, keyword search is superior to semantic search.\n",
    "2.  **When Exact Phrasing is Critical:** Think of legal research (\"must be in writing\"), compliance (\"shall not be disclosed\"), or finding a specific quote from a company all-hands meeting.\n",
    "3.  **As a Pre-Filter:** You can use a keyword filter to dramatically narrow down the search space *before* applying a more computationally expensive semantic search. For example, if a user asks, \"What are the Q3 sales goals for the 'Hydra' project?\", you could first filter all documents to only those tagged with \"Hydra\" and \"Q3,\" and *then* run a semantic search on that much smaller subset.\n",
    "4.  **As Part of a Hybrid Search Strategy:** This is the most common and powerful application. You run a keyword search *and* a semantic search simultaneously and then combine the results. This gives you the best of both worlds: the precision of keyword matching and the broad understanding of semantics. We'll cover this in detail later in the course.\n",
    "\n",
    "-----\n",
    "\n",
    "## Implementing Keyword-Like Search in LangChain\n",
    "\n",
    "This brings us to the practical part. How do we actually *do* this?\n",
    "\n",
    "**An important note:** The core `VectorStoreRetriever` that you've been using is designed for **semantic search**. It takes your query, embeds it into a vector, and looks for other vectors that are close by in geometric space. LangChain doesn't have a built-in, standalone \"KeywordSearchEngine\" in the same way, because its philosophy is rooted in the power of LLMs and embeddings.\n",
    "\n",
    "However, we can achieve the *effect* of keyword search in two primary ways with the tools you already know.\n",
    "\n",
    "### Approach 1: Leveraging Metadata Filters (Most Practical and Recommended)\n",
    "\n",
    "This is the most common and scalable way to integrate keyword-style filtering into your RAG workflow. You already know that `Document` objects have a `page_content` field and a `metadata` dictionary. We can strategically use that `metadata` field to our advantage.\n",
    "\n",
    "During your indexing phase, you can enrich your chunks with metadata tags that act as keywords.\n",
    "\n",
    "Let's see this in action. Imagine we have internal company documents about different projects.\n",
    "\n",
    "```python\n",
    "# First, let's set up our environment\n",
    "# Make sure you have langchain, langchain_openai, langchain_community, chromadb, and python-dotenv installed\n",
    "# pip install langchain langchain_openai langchain_community chromadb python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure you have your OPENAI_API_KEY set in your .env file\n",
    "# OPENAI_API_KEY=\"sk-...\"\n",
    "\n",
    "# 1. Create Documents with Rich Metadata\n",
    "\n",
    "# Notice how we're adding specific, filterable tags to the metadata\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Project Phoenix is focused on leveraging generative AI to improve customer support. The target launch is Q4 2025.\",\n",
    "        metadata={\"project_code\": \"PHX-001\", \"team\": \"AI Research\", \"status\": \"active\", \"quarter\": \"Q4\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The final budget for Project Phoenix has been approved at $1.5M. All expenditures must be tracked.\",\n",
    "        metadata={\"project_code\": \"PHX-001\", \"team\": \"Finance\", \"status\": \"approved\", \"quarter\": \"Q3\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Project Titan aims to overhaul our cloud infrastructure for better scalability. This is a high-priority initiative for Q4.\",\n",
    "        metadata={\"project_code\": \"TTN-002\", \"team\": \"Infrastructure\", \"status\": \"active\", \"quarter\": \"Q4\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A security audit for Project Titan is scheduled for next week. All team members must complete the pre-audit checklist.\",\n",
    "        metadata={\"project_code\": \"TTN-002\", \"team\": \"Security\", \"status\": \"pending_audit\", \"quarter\": \"Q3\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 2. Initialize Embeddings and Vector Store\n",
    "# We still need an embedding model because Chroma is a vector store at heart.\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "vector_store = Chroma.from_documents(docs, embedding_function)\n",
    "\n",
    "# 3. Perform a Search with a Keyword Filter\n",
    "\n",
    "# Let's say we want to find all documents related to the \"Phoenix\" project.\n",
    "# We can use the 'project_code' as our precise keyword.\n",
    "# The query itself can be semantic, but the filter is a hard keyword match.\n",
    "\n",
    "query = \"What is the budget?\"\n",
    "phoenix_docs = vector_store.similarity_search(\n",
    "    query,\n",
    "    # This is the key part! The 'filter' argument performs a metadata search.\n",
    "    filter={\"project_code\": \"PHX-001\"}\n",
    ")\n",
    "\n",
    "print(\"--- Search Results for Project Phoenix (PHX-001) ---\")\n",
    "for doc in phoenix_docs:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\\n\")\n",
    "\n",
    "# Now let's find all active projects in Q4\n",
    "query_q4 = \"What's happening this quarter?\"\n",
    "q4_active_docs = vector_store.similarity_search(\n",
    "    query_q4,\n",
    "    filter={\"status\": \"active\", \"quarter\": \"Q4\"} # You can combine filters!\n",
    ")\n",
    "\n",
    "print(\"--- Search Results for Active Q4 Projects ---\")\n",
    "for doc in q4_active_docs:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\\n\")\n",
    "```\n",
    "\n",
    "What happened here? We performed a semantic search for \"What is the budget?\", but we told ChromaDB to *only* look at documents where the `metadata` dictionary contained `\"project_code\": \"PHX-001\"`. This isn't a pure keyword search across the `page_content`, but it's an incredibly effective and common pattern: **using keywords in metadata to filter and scope a semantic search.**\n",
    "\n",
    "### Approach 2: Simple Pythonic Filtering (For Conceptual Understanding)\n",
    "\n",
    "What if you wanted to replicate the *actual mechanism* of searching the `page_content` for a keyword? You could do this with a simple Python function, especially within a LangChain Expression Language (LCEL) chain.\n",
    "\n",
    "**Disclaimer:** This method is for demonstration and learning. It is **not scalable**. Searching through a list of thousands of documents in memory like this would be very slow. Real-world systems use optimized indexing for this. But it's perfect for understanding the concept.\n",
    "\n",
    "Let's build a simple chain that takes a list of documents and filters them with a basic Python `if \"keyword\" in text:` check.\n",
    "\n",
    "```python\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# We will reuse the 'docs' list from the previous example.\n",
    "# Our simple list of 4 documents will act as our entire database.\n",
    "all_documents = docs\n",
    "\n",
    "def simple_keyword_filter(inputs: dict) -> list[Document]:\n",
    "    \"\"\"\n",
    "    A simple, non-scalable function to filter documents based on a keyword.\n",
    "    'inputs' is expected to be a dictionary with 'documents' and 'keyword' keys.\n",
    "    \"\"\"\n",
    "    keyword = inputs[\"keyword\"].lower()\n",
    "    input_docs = inputs[\"documents\"]\n",
    "    \n",
    "    # This is the core logic: iterate and check for the substring.\n",
    "    # We use .lower() to make the search case-insensitive, a common preprocessing step.\n",
    "    filtered_docs = [\n",
    "        doc for doc in input_docs if keyword in doc.page_content.lower()\n",
    "    ]\n",
    "    return filtered_docs\n",
    "\n",
    "# We can wrap this function in a RunnableLambda to use it in a chain.\n",
    "keyword_filter_runnable = RunnableLambda(simple_keyword_filter)\n",
    "\n",
    "# Let's test it! We want to find documents that contain the word \"security\".\n",
    "results = keyword_filter_runnable.invoke({\n",
    "    \"documents\": all_documents,\n",
    "    \"keyword\": \"security\"\n",
    "})\n",
    "\n",
    "print(\"--- Results from Simple Pythonic Keyword Filter for 'security' ---\")\n",
    "for doc in results:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\\n\")\n",
    "\n",
    "# Let's try another one for \"budget\"\n",
    "results_budget = keyword_filter_runnable.invoke({\n",
    "    \"documents\": all_documents,\n",
    "    \"keyword\": \"budget\"\n",
    "})\n",
    "\n",
    "print(\"--- Results from Simple Pythonic Keyword Filter for 'budget' ---\")\n",
    "for doc in results_budget:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\\n\")\n",
    "\n",
    "```\n",
    "\n",
    "This code directly illustrates the \"pattern matching\" concept we discussed. It's crude but effective for showing the mechanism. It also highlights why preprocessing is important—the `lower()` call prevented us from missing a match if the case was different.\n",
    "\n",
    "-----\n",
    "\n",
    "## Troubleshooting & Best Practices for Keyword Search\n",
    "\n",
    "When you rely on keywords, you need to be mindful of their pitfalls.\n",
    "\n",
    "  * **Lexical Gap Awareness:** This is rule \\#1. If you're getting poor results (low recall), the first thing to suspect is the lexical gap. Are there synonyms or alternative phrasings you're not accounting for?\n",
    "  * **Preprocessing is Key:** As shown in our Pythonic example, simple normalization can make a huge difference.\n",
    "      * **Lowercasing:** Convert all text to lowercase to prevent mismatches like \"Apple\" vs. \"apple\".\n",
    "      * **Punctuation Removal:** Decide if punctuation should be removed. Does \"run.\" match \"run\"?\n",
    "  * **Stemming and Lemmatization (Brief Mention):** These are more advanced text preprocessing techniques.\n",
    "      * **Stemming:** Chops words down to a common \"stem\" (e.g., \"running\", \"ran\" -\\> \"run\"). It's fast but can be crude.\n",
    "      * **Lemmatization:** Uses linguistic rules to reduce words to their dictionary form, their \"lemma\" (e.g., \"was\", \"is\" -\\> \"be\"; \"better\" -\\> \"good\"). It's more accurate but slower. You could theoretically integrate these into a `RunnableLambda` for more robust matching.\n",
    "  * **Query Expansion (Brief Mention):** This is the practice of automatically adding synonyms to a user's query. If a user searches for \"car,\" the system might expand the search to `(\"car\" OR \"automobile\" OR \"vehicle\")`. This directly combats the lexical gap.\n",
    "  * **Metadata Strategy:** If you plan to use metadata filtering (Approach 1), you need a good strategy. Plan your tags during the data ingestion phase. Keep them consistent. Is it `\"team\": \"AI\"` or `\"team\": \"AI Research\"`? Consistency is crucial for reliable filtering.\n",
    "\n",
    "-----\n",
    "\n",
    "## Connecting to the Retrieval Workflow\n",
    "\n",
    "Let's update our mental model of the RAG pipeline to see exactly where keyword-based filtering fits. It's not a replacement for the vector store, but a powerful companion to it.\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    subgraph \"Indexing (The Archives)\"\n",
    "        A[Raw Data] --> B{Document Loaders};\n",
    "        B --> C[Documents];\n",
    "        C -- \"Enrich with keyword tags!\" --> D{Text Splitters};\n",
    "        D --> E[Chunks with Metadata];\n",
    "        E --> F{Embedding Model};\n",
    "        F --> G[Vector Embeddings];\n",
    "        G & E --> H[Vector Store];\n",
    "    end\n",
    "\n",
    "    subgraph \"Retrieval & Generation (The Quest)\"\n",
    "        I[User Query] --> J{Query Pre-processing};\n",
    "        J --> K[\"Keyword Search/Filtering <br/>(e.g., on Metadata in Vector Store)\"];\n",
    "        K --> L[Filtered Candidate Chunks];\n",
    "        L -- \"These can be the final context, <br/> or passed to another search step\" --> M[Consolidated Context];\n",
    "        M --> N[Prompt Template];\n",
    "        N --> O[LLM];\n",
    "        O --> P[Generated Answer];\n",
    "    end\n",
    "```\n",
    "\n",
    "As the diagram shows, we can use keyword filtering right at the start of the retrieval process to quickly cull the search space. By filtering the documents in our `VectorStore` using metadata, we create a much smaller, more relevant set of candidates for the LLM to work with.\n",
    "\n",
    "-----\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    ">   * **Core Idea:** Keyword search finds documents containing the **exact words** from a query. It's about literal string matching, not understanding meaning.\n",
    ">   * **Main Weakness:** The **Lexical Gap**. It fails when the user's query uses different words (synonyms, etc.) than the document, leading to low recall (missed documents).\n",
    ">   * **Main Strength:** High **precision** for specific identifiers (product codes, error messages) and exact phrases where wording is critical. It's also fast, simple, and interpretable.\n",
    ">   * **Practical Implementation:** In LangChain, the most effective way to use keywords is by **filtering on metadata** within your `VectorStore` (`vector_store.similarity_search(query, filter={...})`).\n",
    ">   * **Role in RAG:** It's rarely used alone for general Q\\&A. Its power lies in **pre-filtering** a dataset or being combined with semantic search in a **hybrid** system.\n",
    "\n",
    "-----\n",
    "\n",
    "## Exercises & Thought Experiments\n",
    "\n",
    "1.  **Metadata Filtering Practice:** Take the ChromaDB code example from today's lecture.\n",
    "\n",
    "      * Add a new document with the content \"The marketing budget for Q3 is focused on social media campaigns\" and metadata `{\"project_code\": \"MKT-003\", \"team\": \"Marketing\", \"status\": \"active\", \"quarter\": \"Q3\"}`.\n",
    "      * Write a query that finds all documents from the \"Finance\" or \"Marketing\" teams. (Hint: Look up how ChromaDB handles `OR` conditions in filters, or perform two separate searches).\n",
    "      * Perform a search for \"budget\" but *filter out* anything from Project Phoenix.\n",
    "\n",
    "2.  **The Lexical Gap Challenge:**\n",
    "\n",
    "      * Create a single `Document` object where the `page_content` is: \"Our firm's automobiles are high-performance vehicles, and we ensure every ride is inspected for quality.\"\n",
    "      * Using the `simple_keyword_filter` `RunnableLambda` from our lecture, try to find this document using the keyword \"car\".\n",
    "      * Observe that it fails. In a text block, explain exactly why it failed, using the term \"lexical gap.\" Then, list three different keywords that *would* have successfully found this document.\n",
    "\n",
    "3.  **When is Keyword King?** Brainstorm and write down three specific, real-world RAG application scenarios where keyword search would likely be *more* useful and reliable than a pure semantic search. Explain your reasoning for each. (e.g., A system for looking up legal precedents, a chatbot for checking order statuses using an order ID, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43708c-96b5-420f-9f0b-f1b84c1361a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
