{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6d37b2-9c96-4f81-bda7-866c22d37717",
   "metadata": {},
   "source": [
    "# Part 1: What is Langchain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9ac5f-19e2-47d3-82db-adc2108583f0",
   "metadata": {},
   "source": [
    "When you first start working with AI models like ChatGPT or Gemini, things feel simple enough. You send a prompt, you get a response. It feels like magic.\n",
    "\n",
    "For example, using Google's Gemini model with the Langchain integration looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97bff7-2fc9-4ad3-be3a-c6d93a594f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb514d9-d221-4fab-9cc7-7b9e74eafe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"How does AI work?\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376b268-8e66-4a39-88a3-39846f3b0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"You are a cat. Your name is Neko.\"),\n",
    "    contents=\"Hello there\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b463708-2473-4d95-8459-4690a75cba86",
   "metadata": {},
   "source": [
    "The model gives you a fun fact. Great! But as soon as you try to build something more than a toy demoâ€”maybe a chatbot, a document Q\\&A system, or an AI assistantâ€”the cracks start to show.\n",
    "\n",
    "You realize that:\n",
    "\n",
    "* Your prompts get messy and hard to maintain\n",
    "* You need structured, reliable outputs, not just free-flowing text\n",
    "* You want multi-step reasoning or logic, but managing that manually is painful\n",
    "* Your code becomes scattered, fragile, and hard to scale\n",
    "\n",
    "This is exactly the problem Langchain solves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e9ba5-e9c4-4fdb-8415-e78a10bd295a",
   "metadata": {},
   "source": [
    "\n",
    "## So, What is Langchain?\n",
    "\n",
    "Langchain is a **framework that helps you structure AI-powered applications**, especially those built around Large Language Models (LLMs).\n",
    "\n",
    "It doesn't replace your LLM (like Gemini or GPT-4), it wraps around itâ€”bringing order, clarity, and powerful tools for:\n",
    "\n",
    "âœ… Prompt management\n",
    "âœ… Multi-step reasoning (chains)\n",
    "âœ… Output parsing and structured results\n",
    "âœ… Composing reusable, maintainable AI logic\n",
    "\n",
    "Think of Langchain as the missing architectural layer between raw LLMs and real-world AI applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d069ce-4421-4c78-ae7c-57abe757569d",
   "metadata": {},
   "source": [
    "## Why Would You Need a Framework?\n",
    "\n",
    "Letâ€™s pause for a relatable analogy.\n",
    "\n",
    "Imagine trying to build a house using only raw materialsâ€”bricks, cement, woodâ€”with no blueprints, no tools, no organized process. Technically possible, but painful, error-prone, and messy.\n",
    "\n",
    "Langchain gives you the **blueprints and tools** to build AI apps in a structured, maintainable way.\n",
    "\n",
    "---\n",
    "\n",
    "## What Does Langchain Actually Do?\n",
    "\n",
    "At its core, Langchain provides:\n",
    "\n",
    "* A standard way to build prompts and messages\n",
    "* Tools to chain multiple steps of logic together\n",
    "* Clean handling of LLM outputsâ€”whether plain text or structured formats\n",
    "* Flexibility to swap LLM providers if needed\n",
    "\n",
    "All while keeping your code organized and scalable.\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Illustration: From Chaos to Structure\n",
    "\n",
    "Let me show you how raw LLM interaction compares to Langchain-powered structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e5fc85-a181-46b9-b2ae-e0c81d225d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://python.langchain.com/assets/images/ecosystem_packages-32943b32657e7a187770c9b585f22a64.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "image_url = \"https://python.langchain.com/assets/images/ecosystem_packages-32943b32657e7a187770c9b585f22a64.png\"\n",
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9743cd-8619-4a46-906e-4e76a8bf58a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86fbb2c-d9d7-4293-b30b-c75a21787a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Step 1: Define your LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "\n",
    "# Step 2: Define a prompt template with placeholders\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Step 3: Insert your dynamic variable\n",
    "messages = prompt.format_messages(question=\"What is a fun fact about the ocean?\")\n",
    "\n",
    "# Step 4: Send to LLM\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016f557-5bb6-44dd-abbc-fef0815fda72",
   "metadata": {},
   "source": [
    "\n",
    "Notice:\n",
    "\n",
    "âœ”ï¸ Prompts are clean, reusable, and readable\n",
    "âœ”ï¸ Variables like `{question}` make it dynamic\n",
    "âœ”ï¸ You separate logic from contentâ€”just like good software design\n",
    "\n",
    "---\n",
    "\n",
    "## Beyond Prompts: Chains and More\n",
    "\n",
    "Langchain isnâ€™t just about prompts. It introduces **Chains**, which let you link together:\n",
    "\n",
    "* Prompt generation\n",
    "* LLM invocation\n",
    "* Output handling\n",
    "\n",
    "All in one neat, maintainable flow.\n",
    "\n",
    "Hereâ€™s a sneak peek (weâ€™ll explore this in detail later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec2378e-ab80-4bbb-9186-d15fda4b5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "result = chain.invoke({\"question\": \"What's the capital of France?\"})\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87459e9d-aca5-44f7-b0e7-d719b799ed5c",
   "metadata": {},
   "source": [
    "\n",
    "Instead of stitching everything manually, the **Chain** handles the full flow for you.\n",
    "\n",
    "---\n",
    "\n",
    "## Where Does Langchain Fit in the AI Development Picture?\n",
    "\n",
    "Picture this:\n",
    "\n",
    "ðŸ› ï¸ You have your LLM â€” Gemini, GPT, Claude, etc.\n",
    "ðŸ› ï¸ You need to build a real application â€” chatbot, assistant, RAG system, etc.\n",
    "ðŸ› ï¸ You want maintainable, scalable code â€” not a tangle of messy prompt strings\n",
    "\n",
    "Langchain sits perfectly in between:\n",
    "\n",
    "```\n",
    "Your App Logic  --->  Langchain  --->  LLM (Gemini, GPT, etc.)\n",
    "```\n",
    "\n",
    "It gives structure to how your app talks to the LLM, handles responses, and composes logic.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Langchain is your **AI app orchestrator**. It:\n",
    "\n",
    "âœ… Brings structure to how you interact with LLMs\n",
    "âœ… Simplifies prompts, outputs, and multi-step logic\n",
    "âœ… Makes your AI projects more maintainable and production-ready\n",
    "\n",
    "Without it, building anything beyond basic demos with LLMs becomes painful. With it, your AI development feels like software engineeringâ€”not duct-tape hacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd05810-62b1-4dda-8cd6-aaa9bf984e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
